{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b2e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTIPROBE = True # This determines if TPrime is used to align multiple streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc0c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No files to process found.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import subprocess, sys, time\n",
    "\n",
    "dt_folder = Path(r\"C:\\Users\\Data Analysis\\Desktop\\project_trainingAggression\\Data\")\n",
    "\n",
    "run_folders = [rf.parent for rf in sorted(dt_folder.rglob(\"*nidq.bin\"))]\n",
    "catGT_runs = [cgt.name.split(\"catgt_\")[1] for cgt in sorted(dt_folder.rglob(\"catgt*\"))]\n",
    "\n",
    "unprocessed_neuralData_folders = [rf for rf in run_folders if rf.name not in catGT_runs]\n",
    "\n",
    "if len(unprocessed_neuralData_folders) == 0:\n",
    "    print(\"No files to process found.\")\n",
    "else: \n",
    "    print(\"Runs to process with catGT:\")\n",
    "    for rf in unprocessed_neuralData_folders:\n",
    "        print(\"  \", rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd3c0b6",
   "metadata": {},
   "source": [
    "# **Pre-processing**\n",
    "\n",
    "https://billkarsh.github.io/SpikeGLX/help/syncEdges/Sync_edges/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7cfc09",
   "metadata": {},
   "source": [
    "## catGT: Single probe demultiplexing corrections and TTL event extraction\n",
    "\n",
    "**Documentation:** file:///C:/Users/Data%20Analysis/Desktop/CatGT-win/ReadMe.html\n",
    "\n",
    "If Exit code 42, see CatGT log in \\project_trainingAggression\\Code\\CatGT.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8810b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "catGT = (r\"C:\\Users\\Data Analysis\\Desktop\\CatGT-win\\CatGT.exe\")\n",
    "\n",
    "for folderRun in unprocessed_neuralData_folders:\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    dataFolder = folderRun.parent\n",
    "    spikeGLX_run = folderRun.name \n",
    "    if (\"_g0\" in spikeGLX_run):\n",
    "        spikeGLX_run = spikeGLX_run[0:-3]# Removes \"_g0\" from filename\n",
    "\n",
    "    print(f\"Multiplexer temporal shift correction in session: {spikeGLX_run}\")\n",
    "\n",
    "    cmd = [\n",
    "            str(catGT),\n",
    "            f\"-dir={dataFolder}\",  \n",
    "            f\"-run={spikeGLX_run}\",\n",
    "            \"-g=0\",\n",
    "            \"-t=0\",            \n",
    "            \"-ap\",              # Process Action Potential (.ap.bin) files\n",
    "            \"-prb=0:2\",         # Probe 1 to 3\n",
    "            \"-ni\",              # Process the auxiliary data (.niqd.bin) containing both Analog and Digital channels\n",
    "            \"-prb_fld\",         # 1 probe per folder\n",
    "            \"-maxsecs=1205.00\", # 20 min + 5 seconds\n",
    "\n",
    "\n",
    "            # ========= -xd = js,ip,word,bit,pulsewidth(ms),tol(ms) =========\n",
    "\n",
    "            \"-xid=0,0,3,2,50,5\",               # Sweetened milk events: falling edges (P.02)\n",
    "            #\"-xd=0,0,8,2,15000, 1000\",        # Sweetened milk events: rising edges (P.02)\n",
    "\n",
    "            \"-xd=0,0,3,3,0\",                   # LED red light ON: rising edges (P.03)\n",
    "            \"-xid=0,0,3,3,360000,5000\",        # LED white light ON: falling edge (P.03)  \n",
    "\n",
    "            \"-xd=0,0,3,4, 1000000,500000\",     # Gate OPEN: rising edge (P.04)\n",
    "\n",
    "            \"-xd=0,0,3,5,3500,500\",            # uArm ON: rising edges (P.05)\n",
    "            \"-xid=0,0,3,5,11000,3000\",         # uArm OFF: falling edges (P.05) (Not all of them will be picked up but it is good to know the average trial duration)\n",
    "\n",
    "            f\"-dest={dataFolder}\",\n",
    "            \"-out_prb_fld\"\n",
    "          ]\n",
    "    \n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "    for line in p.stdout:\n",
    "        sys.stdout.write(line)\n",
    "    rc = p.wait()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"Exit code: {rc}. Running time (1 SpikeGLX run): {(end - start)/60: .2f} min.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f384aac",
   "metadata": {},
   "source": [
    "## kilosort4: Spike sorting after High-Pass FIR filter (300 Hz), Common Average Referencing (CAR) and whitening\n",
    "\n",
    "**Documentation:** https://kilosort.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17bfb2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No files to process found.\n"
     ]
    }
   ],
   "source": [
    "def filter_unprocessed(files):\n",
    "    \"\"\"Keep only those whose neuralData parent folder has no kilosort4/ directory.\"\"\"\n",
    "    out = []\n",
    "    for f in files:\n",
    "        kilosort_out = f.parent / \"kilosort4\"\n",
    "        if not kilosort_out.exists():\n",
    "            out.append(f)\n",
    "    return out\n",
    "\n",
    "def read_spikeglx_meta(meta_path: Path) -> dict:\n",
    "    \"\"\"Parse a SpikeGLX .meta into a dict.\"\"\"\n",
    "    metafile = {}\n",
    "    with meta_path.open('r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if '=' in line:\n",
    "                k, v = line.strip().split('=', 1)\n",
    "                metafile[k] = v\n",
    "    return metafile\n",
    "\n",
    "tcat_bin_files  = filter_unprocessed(sorted(dt_folder.rglob(\"*_tcat.imec*.ap.bin\")))\n",
    "tcat_meta_files = filter_unprocessed(sorted(dt_folder.rglob(\"*_tcat.imec*.ap.meta\")))\n",
    "\n",
    "if len(tcat_bin_files) == 0:\n",
    "    print(\" No files to process found.\")\n",
    "else:\n",
    "    print(\"Runs to spike sort:\")\n",
    "    for rf in tcat_bin_files:\n",
    "        print(\"  \", rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78685a0a",
   "metadata": {},
   "source": [
    "**Kilosort4 output files description:** https://kilosort.readthedocs.io/en/stable/export_files.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c02b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kilosort\n",
    "import torch\n",
    "\n",
    "for it, probe_run in enumerate(tcat_bin_files):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    print(f\"\\n ============= Running kilosort4 on {probe_run.name} ============= \")\n",
    "\n",
    "    metafile = read_spikeglx_meta(tcat_meta_files[it])\n",
    "\n",
    "    settings = {\n",
    "                'filename': probe_run,\n",
    "                'n_chan_bin': 385,                                      # 384 + 1 because synch channel is included\n",
    "                'fs': float(metafile[\"imSampRate\"]),                    # Each headstage has a slight different clock/sampling rate. This is was obtained through the synch channel after a 40 min calibration run on SpikeGLX \n",
    "                'highpass_cutoff': 300.0              \n",
    "            }\n",
    "\n",
    "    ops, st, clu, tF, Wall, similar_templates, is_ref, est_contam_rate, kept_spikes = kilosort.run_kilosort(\n",
    "                                                                                        settings=settings,\n",
    "                                                                                        do_CAR = True,                                         # Common Average Referencing\n",
    "                                                                                        probe_name = \"neuropixPhase3B2_kilosortChanMap.mat\",   # Neuropixels 1.0 channel map \n",
    "                                                                                        data_dtype = 'int16',                                   \n",
    "                                                                                        #save_preprocessed_copy = True,                         # Saves a copy pre-processed copy of the data before spike sorting\n",
    "                                                                                        results_dir = f\"{tcat_meta_files[it].parent}/kilosort4\",              \n",
    "                                                                                        device=torch.device('cuda')              \n",
    "                                                                                        )\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"\\nRunning time (1 probe): {(end - start)/60: .2f} min.\\n\")\n",
    "\n",
    "    print(\" ================================================================\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61deac0b",
   "metadata": {},
   "source": [
    "## TPrime: Align events across probes and NI analog + TTL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21cacd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# First a conversion from samples to seconds is required in the spike sorted data\n",
    "\n",
    "spk_time_files = dt_folder.rglob(\"*spike_times.npy\")\n",
    "aready_processed = [ard_prc.parent for ard_prc in (dt_folder.rglob(\"*spike_seconds.npy\"))]\n",
    "\n",
    "spk_time_files_2proc = [spk_file for spk_file in spk_time_files if spk_file.parent not in aready_processed]\n",
    "\n",
    "for spk_file in spk_time_files_2proc:\n",
    "\n",
    "    probe_folder = spk_file.parent.parent\n",
    "\n",
    "    print(spk_file, probe_folder)\n",
    "\n",
    "    metafile = read_spikeglx_meta(next(probe_folder.glob(\"*.meta\")))\n",
    "\n",
    "    fl = np.load(spk_file)\n",
    "\n",
    "    samples_to_seconds = fl/float(metafile[\"imSampRate\"])\n",
    "    newfile_path = spk_file.parent / \"spike_seconds.npy\"\n",
    "\n",
    "    np.save(newfile_path, samples_to_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a7c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MULTIPROBE:\n",
    "    \n",
    "    tprime = (r\"C:\\Users\\Data Analysis\\Desktop\\TPrime-win\\TPrime.exe\")\n",
    "\n",
    "    already_converted = [stream.parent.parent.parent for stream in dt_folder.rglob(\"*spike_seconds_prb*_adj.npy\")]\n",
    "\n",
    "    all_master_streams_ni = dt_folder.rglob(\"*nidq.xd_3_0_500.txt\")\n",
    "    master_streams_ni_2proc = [stream for stream in all_master_streams_ni if stream.parent not in already_converted]\n",
    "\n",
    "    for id, ni_stream in enumerate(master_streams_ni_2proc):\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        print(f\"Aligning session: {ni_stream.parent}\")\n",
    "\n",
    "        prb_streams = [prb for prb in (ni_stream.parent.rglob(\"*tcat.imec*.ap.xd*\"))]\n",
    "\n",
    "        spk_sec_prb0 = next(prb_streams[0].parent.rglob(\"*spike_seconds.npy\"))\n",
    "        conv_spk_sec_prb0 = spk_sec_prb0.parent / \"spike_seconds_prb0_adj.npy\"\n",
    "\n",
    "        spk_sec_prb1 = next(prb_streams[1].parent.rglob(\"*spike_seconds.npy\"))\n",
    "        conv_spk_sec_prb1 = spk_sec_prb1.parent / \"spike_seconds_prb1_adj.npy\"\n",
    "\n",
    "        spk_sec_prb2 = next(prb_streams[2].parent.rglob(\"*spike_seconds.npy\"))\n",
    "        conv_spk_sec_prb2 = spk_sec_prb2.parent / \"spike_seconds_prb2_adj.npy\"\n",
    "\n",
    "        cmd = [\n",
    "        tprime,\n",
    "        \"-syncperiod=1.0\",\n",
    "        f\"-tostream={ni_stream}\",\n",
    "        f\"-fromstream=1,{prb_streams[0]}\",\n",
    "        f\"-fromstream=2,{prb_streams[1]}\",\n",
    "        f\"-fromstream=3,{prb_streams[2]}\",\n",
    "        f\"-events=1,{spk_sec_prb0},{conv_spk_sec_prb0}\",\n",
    "        f\"-events=2,{spk_sec_prb1},{conv_spk_sec_prb1}\",\n",
    "        f\"-events=3,{spk_sec_prb2},{conv_spk_sec_prb2}\",\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "        for line in p.stdout:\n",
    "            sys.stdout.write(line)\n",
    "        rc = p.wait()\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        print(f\"Exit code: {rc}. Running time (1 SpikeGLX run): {(end - start): .2f} sec.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kilosort",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
